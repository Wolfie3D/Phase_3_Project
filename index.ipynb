{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "As a leading data mining and statistical computation company, Chris Tech specializes in transforming raw data into valuable insights. Signature Realtors, recognizing our expertise, has entrusted us with a strategic assignment. Our collaborative venture aims to develop a sophisticated price estimation model for houses, leveraging data extracted from jiji.com. This report delineates the meticulous approach we have adopted in the initial phases of the CRISP-DM framework to ensure the success of the project.\n",
    "### Business Objectives:\n",
    "Our first objective in this collaboration is to create a precise price estimation model for houses, a task that aligns seamlessly with our core competencies in data mining and statistical computation. Through in-depth discussions with Signature Realtors, we've established clear success criteria, emphasizing accurate price predictions, model interpretability, and seamless integration into their existing systems. Our commitment to understanding the business objectives sets the stage for a purposeful and effective data mining project.\n",
    "### The Situation:\n",
    "We recognize the importance of a comprehensive understanding of the project's context. Assessing the situation involves identifying the required resources, project requirements, potential risks, and conducting a cost-benefit analysis. We've meticulously evaluated the availability of human resources with expertise in data scraping and model development. Simultaneously, we've assessed the technological requirements and time commitments necessary for the successful completion of the project. Our risk assessment has identified potential challenges such as legal issues related to data scraping, data quality concerns, and model interpretability challenges. This detailed situational analysis, including a cost-benefit evaluation, ensures that our collaboration with Signature Realtors is grounded in a robust foundation.\n",
    "### Data Mining Goals:\n",
    "The technical objectives of our data mining process have been clearly defined. These include specifying data cleaning processes, feature engineering techniques, model selection criteria, and the metrics by which we'll evaluate the success of our models. Additionally, we've outlined the data requirements, explicitly specifying the types of features needed for our price estimation modelâ€”factors such as size, bedrooms, bathrooms, neighborhood characteristics, and country-specific attributes. Our meticulous approach to determining data mining goals ensures that we have a roadmap for technical success aligned with the overall business objectives.\n",
    "### Project Plan:\n",
    "Selecting appropriate technologies and tools is paramount to the success of our project. We've chosen tools that facilitate efficient data scraping, robust data preprocessing, and streamlined model development. Our detailed project plan encompasses timelines and milestones for each phase of the project, providing clarity on tasks related to data scraping, preprocessing, model development, and evaluation. Additionally, we've established a communication plan to ensure seamless collaboration with Signature Realtors, fostering transparency and mutual understanding throughout the project lifecycle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data:\n",
    "The first task involves acquiring the necessary data and loading it into our analysis tool. Given that our project involves scraping data from jiji.com, this task is crucial for kickstarting the data mining process. The data collected should encompass the features essential for our price estimation model, such as house size, bedrooms, bathrooms, neighborhood details, and country-specific attributes. This task sets the stage for subsequent analysis, ensuring that we have the raw materials needed for our modeling endeavors.\n",
    "\n",
    "for more information checkout: 'DATA\\data_description.txt'\n",
    "\n",
    "and the scrapper notebook : \"APP\\scrapper.ipynb\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, ShuffleSplit, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from joblib import dump\n",
    "\n",
    "\n",
    "# preferences\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cost</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Furnished</th>\n",
       "      <th>Space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KSh 7,500,000</td>\n",
       "      <td>3bdrm House in Tabasamu Annex, Kalimoni for Sale</td>\n",
       "      <td>3 Bedroom Houses available for viewing. \\nOthe...</td>\n",
       "      <td>Kiambu, Juja</td>\n",
       "      <td>3 bedrooms</td>\n",
       "      <td>2 bathrooms</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>300sqm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KSh 16,500,000</td>\n",
       "      <td>4bdrm Maisonette in Milimani Estate for Sale</td>\n",
       "      <td>I am selling a 4bedroom massionate sitted on a...</td>\n",
       "      <td>Kiambu, Ruiru</td>\n",
       "      <td>4 bedrooms</td>\n",
       "      <td>3 bathrooms</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>165sqm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KSh 4,325,000</td>\n",
       "      <td>2bdrm Block of Flats in Estate, Old Junction f...</td>\n",
       "      <td>Affordable Housing in Ruiru\\nMost of the block...</td>\n",
       "      <td>Kiambu, Ruiru</td>\n",
       "      <td>2 bedrooms</td>\n",
       "      <td>2 bathrooms</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>75sqm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KSh 4,500,000</td>\n",
       "      <td>Studio Apartment in Kilimani for sale</td>\n",
       "      <td>Property description\\n* modern studio apartmen...</td>\n",
       "      <td>Nairobi, Kilimani</td>\n",
       "      <td>1 bedroom</td>\n",
       "      <td>1 bathroom</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>35sqm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KSh 35,000,000</td>\n",
       "      <td>Furnished 4bdrm Mansion in Palm Tree, Ukunda f...</td>\n",
       "      <td>Four bedroom mansion in diani! @\\nlooking for ...</td>\n",
       "      <td>Kwale, Ukunda</td>\n",
       "      <td>4 bedrooms</td>\n",
       "      <td>5 bathrooms</td>\n",
       "      <td>Furnished</td>\n",
       "      <td>1000sqm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KSh 8,800,000</td>\n",
       "      <td>2bdrm Apartment in Kcc Estate, Umoja I for sale</td>\n",
       "      <td>3bedroomed house for sale.* \\nPlus a one room\\...</td>\n",
       "      <td>Nairobi, Umoja</td>\n",
       "      <td>2 bedrooms</td>\n",
       "      <td>3 bathrooms</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>10sqm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KSh 6,500,000</td>\n",
       "      <td>3bdrm Bungalow in Rimpa for Sale</td>\n",
       "      <td>Newly built 3 bedroom bungalow in a gated comm...</td>\n",
       "      <td>Kajiado, Ongata Rongai</td>\n",
       "      <td>3 bedrooms</td>\n",
       "      <td>2 bathrooms</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>200sqm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KSh 42,000,000</td>\n",
       "      <td>4bdrm Townhouse/Terrace in Loresho Ridge Estat...</td>\n",
       "      <td>Property type: House \\nOffer type: For sale \\n...</td>\n",
       "      <td>Nairobi, Westlands</td>\n",
       "      <td>4 bedrooms</td>\n",
       "      <td>5 bathrooms</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>245sqm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KSh 15,000,000</td>\n",
       "      <td>4bdrm Maisonette in Transview, Mombasa Road fo...</td>\n",
       "      <td>4bedroom town house for sale. With SQ With a k...</td>\n",
       "      <td>Nairobi, Mombasa Road</td>\n",
       "      <td>4 bedrooms</td>\n",
       "      <td>4 bathrooms</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>450sqm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KSh 7,300,000</td>\n",
       "      <td>1bdrm Apartment in Kileleshwa Estate for sale</td>\n",
       "      <td>Purchase these very spacious and very luxuriou...</td>\n",
       "      <td>Nairobi, Kileleshwa</td>\n",
       "      <td>1 bedroom</td>\n",
       "      <td>2 bathrooms</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>78sqm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Cost                                              Title  \\\n",
       "0   KSh 7,500,000   3bdrm House in Tabasamu Annex, Kalimoni for Sale   \n",
       "1  KSh 16,500,000       4bdrm Maisonette in Milimani Estate for Sale   \n",
       "2   KSh 4,325,000  2bdrm Block of Flats in Estate, Old Junction f...   \n",
       "3   KSh 4,500,000              Studio Apartment in Kilimani for sale   \n",
       "4  KSh 35,000,000  Furnished 4bdrm Mansion in Palm Tree, Ukunda f...   \n",
       "5   KSh 8,800,000    2bdrm Apartment in Kcc Estate, Umoja I for sale   \n",
       "6   KSh 6,500,000                   3bdrm Bungalow in Rimpa for Sale   \n",
       "7  KSh 42,000,000  4bdrm Townhouse/Terrace in Loresho Ridge Estat...   \n",
       "8  KSh 15,000,000  4bdrm Maisonette in Transview, Mombasa Road fo...   \n",
       "9   KSh 7,300,000      1bdrm Apartment in Kileleshwa Estate for sale   \n",
       "\n",
       "                                         Description                Location  \\\n",
       "0  3 Bedroom Houses available for viewing. \\nOthe...            Kiambu, Juja   \n",
       "1  I am selling a 4bedroom massionate sitted on a...           Kiambu, Ruiru   \n",
       "2  Affordable Housing in Ruiru\\nMost of the block...           Kiambu, Ruiru   \n",
       "3  Property description\\n* modern studio apartmen...       Nairobi, Kilimani   \n",
       "4  Four bedroom mansion in diani! @\\nlooking for ...           Kwale, Ukunda   \n",
       "5  3bedroomed house for sale.* \\nPlus a one room\\...          Nairobi, Umoja   \n",
       "6  Newly built 3 bedroom bungalow in a gated comm...  Kajiado, Ongata Rongai   \n",
       "7  Property type: House \\nOffer type: For sale \\n...      Nairobi, Westlands   \n",
       "8  4bedroom town house for sale. With SQ With a k...   Nairobi, Mombasa Road   \n",
       "9  Purchase these very spacious and very luxuriou...     Nairobi, Kileleshwa   \n",
       "\n",
       "     Bedrooms    Bathrooms       Furnished    Space  \n",
       "0  3 bedrooms  2 bathrooms     Unfurnished   300sqm  \n",
       "1  4 bedrooms  3 bathrooms     Unfurnished   165sqm  \n",
       "2  2 bedrooms  2 bathrooms     Unfurnished    75sqm  \n",
       "3   1 bedroom   1 bathroom     Unfurnished    35sqm  \n",
       "4  4 bedrooms  5 bathrooms       Furnished  1000sqm  \n",
       "5  2 bedrooms  3 bathrooms     Unfurnished    10sqm  \n",
       "6  3 bedrooms  2 bathrooms  Semi-Furnished   200sqm  \n",
       "7  4 bedrooms  5 bathrooms     Unfurnished   245sqm  \n",
       "8  4 bedrooms  4 bathrooms     Unfurnished   450sqm  \n",
       "9   1 bedroom  2 bathrooms     Unfurnished    78sqm  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "data = pd.read_csv('DATA\\\\finalData.csv')\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    # Drop rows with null values\n",
    "    df_cleaned = df.dropna()\n",
    "    \n",
    "    # Drop duplicate rows\n",
    "    df_cleaned = df_cleaned.drop_duplicates()\n",
    "    \n",
    "    # Reset the index after dropping rows\n",
    "    df_cleaned = df_cleaned.reset_index(drop=True)\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "data = clean_dataframe(data)\n",
    "\n",
    "#chck the top ten raws\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8838 entries, 0 to 8837\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Cost         8838 non-null   object\n",
      " 1   Title        8838 non-null   object\n",
      " 2   Description  8838 non-null   object\n",
      " 3   Location     8838 non-null   object\n",
      " 4   Bedrooms     8838 non-null   object\n",
      " 5   Bathrooms    8838 non-null   object\n",
      " 6   Furnished    8838 non-null   object\n",
      " 7   Space        8838 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 552.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cost', 'Title', 'Description', 'Location', 'Bedrooms', 'Bathrooms',\n",
       "       'Furnished', 'Space'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cost</th>\n",
       "      <td>8838</td>\n",
       "      <td>539</td>\n",
       "      <td>KSh 7,500,000</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <td>8838</td>\n",
       "      <td>4964</td>\n",
       "      <td>2bdrm Apartment in Kilimani for sale</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Description</th>\n",
       "      <td>8838</td>\n",
       "      <td>7234</td>\n",
       "      <td>BUNGALOW HOUSE ON SALE ALONG THIKA RD RUIRU KI...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>8838</td>\n",
       "      <td>214</td>\n",
       "      <td>Nairobi, Kilimani</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bedrooms</th>\n",
       "      <td>8838</td>\n",
       "      <td>13</td>\n",
       "      <td>3 bedrooms</td>\n",
       "      <td>3021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bathrooms</th>\n",
       "      <td>8838</td>\n",
       "      <td>13</td>\n",
       "      <td>2 bathrooms</td>\n",
       "      <td>2283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Furnished</th>\n",
       "      <td>8838</td>\n",
       "      <td>3</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>7433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Space</th>\n",
       "      <td>8838</td>\n",
       "      <td>621</td>\n",
       "      <td>500sqm</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count unique                                                top  \\\n",
       "Cost         8838    539                                      KSh 7,500,000   \n",
       "Title        8838   4964               2bdrm Apartment in Kilimani for sale   \n",
       "Description  8838   7234  BUNGALOW HOUSE ON SALE ALONG THIKA RD RUIRU KI...   \n",
       "Location     8838    214                                  Nairobi, Kilimani   \n",
       "Bedrooms     8838     13                                         3 bedrooms   \n",
       "Bathrooms    8838     13                                        2 bathrooms   \n",
       "Furnished    8838      3                                        Unfurnished   \n",
       "Space        8838    621                                             500sqm   \n",
       "\n",
       "             freq  \n",
       "Cost          249  \n",
       "Title         100  \n",
       "Description     6  \n",
       "Location      766  \n",
       "Bedrooms     3021  \n",
       "Bathrooms    2283  \n",
       "Furnished    7433  \n",
       "Space         397  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8838, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data:\n",
    "The first task in the Data Preparation phase involves determining which data sets will be used for modeling and documenting the reasons for inclusion/exclusion. In the context of our project, this task is pivotal for selecting the relevant features and ensuring that the chosen data aligns with the objectives of creating a price estimation model. Decisions made during this task directly impact the effectiveness and accuracy of the subsequent modeling steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL Data_Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ETL process encompasses a series of functions tailored for preprocessing real estate listing data. The 'split_location,' 'process_bedrooms,' 'process_bathrooms,' 'process_space,' 'remove_ksh,' 'process_title,' and 'process_description' functions each address specific columns, extracting, cleaning, and transforming information. The ColumnTransformer, known as ETL, applies these functions to relevant columns, producing a new DataFrame named preprocessed_data. The resulting dataset includes essential features such as 'County,' 'Neighborhood,' 'Bedroom,' 'Bathroom,' 'Size,' 'Type,' 'Price,' 'Quality,' and 'Furnished.' Columns not explicitly transformed are retained. This final preprocessed dataset provides a structured and cleaned foundation for subsequent analyses, particularly in the context of real estate pricing based on diverse features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_location(df):\n",
    "    df[['County', 'Neighborhood']] = df['Location'].str.split(', ', n=1, expand=True)\n",
    "    df['County'] = df['County'].str.strip()\n",
    "    df['Neighborhood'] = df['Neighborhood'].str.strip()\n",
    "    df = df.drop('Location', axis=1)\n",
    "    return df\n",
    "\n",
    "def process_bedrooms(df):\n",
    "    df['Bedrooms'] = df['Bedrooms'].apply(lambda x: x.split()[0] if isinstance(x, str) else x)\n",
    "    return df[['Bedrooms']]\n",
    "\n",
    "def process_bathrooms(df):\n",
    "    df['Bathrooms'] = df['Bathrooms'].apply(lambda x: x.split()[0] if isinstance(x, str) else x)\n",
    "    return df[['Bathrooms']]\n",
    "\n",
    "def process_space(df):\n",
    "    df['Space'] = df['Space'].apply(lambda x: x.replace('sqm', '').strip() if isinstance(x, str) else x)\n",
    "    return df[['Space']]\n",
    "\n",
    "def remove_ksh(df):\n",
    "    df['Cost'] = df['Cost'].apply(lambda x: x.replace('KSh', '').replace(',', '').strip() if isinstance(x, str) else x)\n",
    "    return df[['Cost']]\n",
    "\n",
    "def process_title(df):\n",
    "    keywords = ['Apartment', 'Villa', 'Bungalow', 'Maisonette', 'House', 'Mansion', 'flat']\n",
    "    df['Type'] = df['Title'].apply(lambda title: next((word for word in keywords if word.lower() in title.lower()), np.nan))\n",
    "    return df[['Type']]\n",
    "\n",
    "def process_description(df):\n",
    "    keywords = ['luxury', 'executive', 'magnificent', \n",
    "                'modern', 'ensuite', 'opulent', 'newly', \n",
    "                'Spacious', 'Residential', 'equipped',\n",
    "                ]\n",
    "    df['Quality'] = df['Description'].apply(lambda desc: 'good' if any(keyword in desc.lower() for keyword in keywords) else 'moderate')\n",
    "    return df[['Quality']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETL = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('county_and_Neighborhood', FunctionTransformer(split_location, validate=False), ['Location']),\n",
    "        ('process_bedrooms', FunctionTransformer(process_bedrooms, validate=False), ['Bedrooms']),\n",
    "        ('process_bathrooms', FunctionTransformer(process_bathrooms, validate=False), ['Bathrooms']),\n",
    "        ('process_space', FunctionTransformer(process_space, validate=False), ['Space']),\n",
    "        ('process_title', FunctionTransformer(process_title, validate=False), ['Title']),\n",
    "        ('remove_ksh', FunctionTransformer(remove_ksh, validate=False), ['Cost']),\n",
    "        ('process_description', FunctionTransformer(process_description, validate=False), ['Description']),\n",
    "    ],\n",
    "    remainder='passthrough'  # Include other columns as-is\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Bedroom</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Size</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Furnished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kiambu</td>\n",
       "      <td>Juja</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>House</td>\n",
       "      <td>7500000</td>\n",
       "      <td>moderate</td>\n",
       "      <td>Unfurnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kiambu</td>\n",
       "      <td>Ruiru</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>165</td>\n",
       "      <td>Maisonette</td>\n",
       "      <td>16500000</td>\n",
       "      <td>moderate</td>\n",
       "      <td>Unfurnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kiambu</td>\n",
       "      <td>Ruiru</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>flat</td>\n",
       "      <td>4325000</td>\n",
       "      <td>moderate</td>\n",
       "      <td>Unfurnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nairobi</td>\n",
       "      <td>Kilimani</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>4500000</td>\n",
       "      <td>good</td>\n",
       "      <td>Unfurnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kwale</td>\n",
       "      <td>Ukunda</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>Mansion</td>\n",
       "      <td>35000000</td>\n",
       "      <td>moderate</td>\n",
       "      <td>Furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nairobi</td>\n",
       "      <td>Umoja</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>8800000</td>\n",
       "      <td>moderate</td>\n",
       "      <td>Unfurnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kajiado</td>\n",
       "      <td>Ongata Rongai</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>Bungalow</td>\n",
       "      <td>6500000</td>\n",
       "      <td>good</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nairobi</td>\n",
       "      <td>Westlands</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>245</td>\n",
       "      <td>House</td>\n",
       "      <td>42000000</td>\n",
       "      <td>moderate</td>\n",
       "      <td>Unfurnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nairobi</td>\n",
       "      <td>Mombasa Road</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>450</td>\n",
       "      <td>Maisonette</td>\n",
       "      <td>15000000</td>\n",
       "      <td>moderate</td>\n",
       "      <td>Unfurnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nairobi</td>\n",
       "      <td>Kileleshwa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>7300000</td>\n",
       "      <td>moderate</td>\n",
       "      <td>Unfurnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    County   Neighborhood Bedroom Bathroom  Size        Type     Price  \\\n",
       "0   Kiambu           Juja       3        2   300       House   7500000   \n",
       "1   Kiambu          Ruiru       4        3   165  Maisonette  16500000   \n",
       "2   Kiambu          Ruiru       2        2    75        flat   4325000   \n",
       "3  Nairobi       Kilimani       1        1    35   Apartment   4500000   \n",
       "4    Kwale         Ukunda       4        5  1000     Mansion  35000000   \n",
       "5  Nairobi          Umoja       2        3    10   Apartment   8800000   \n",
       "6  Kajiado  Ongata Rongai       3        2   200    Bungalow   6500000   \n",
       "7  Nairobi      Westlands       4        5   245       House  42000000   \n",
       "8  Nairobi   Mombasa Road       4        4   450  Maisonette  15000000   \n",
       "9  Nairobi     Kileleshwa       1        2    78   Apartment   7300000   \n",
       "\n",
       "    Quality       Furnished  \n",
       "0  moderate     Unfurnished  \n",
       "1  moderate     Unfurnished  \n",
       "2  moderate     Unfurnished  \n",
       "3      good     Unfurnished  \n",
       "4  moderate       Furnished  \n",
       "5  moderate     Unfurnished  \n",
       "6      good  Semi-Furnished  \n",
       "7  moderate     Unfurnished  \n",
       "8  moderate     Unfurnished  \n",
       "9  moderate     Unfurnished  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data = ETL.fit_transform(data)\n",
    "preprocessed_data = pd.DataFrame(preprocessed_data)\n",
    "preprocessed_data.columns = ['County','Neighborhood',  'Bedroom', 'Bathroom', 'Size', 'Type', 'Price', 'Quality', 'Furnished']\n",
    "preprocessed_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessed_data.drop('Price', axis=1)\n",
    "y = preprocessed_data['Price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The transformations are organized into a ColumnTransformer named feature_engineering, which applies distinct processes to different subsets of features. The 'One_Hot_Encode' transformation utilizes one-hot encoding on categorical columns ('Neighborhood', 'County', 'Type', 'Quality', 'Furnished'), dropping the first category to avoid multicollinearity and ignoring unknown values. Additionally, it incorporates a frequency threshold of 20 to handle less frequent categories. The 'Scaller' transformation standardizes numerical features ('Size', 'Bathroom', 'Bedroom') using StandardScaler. This ensures that these features are on a consistent scale, preventing one from dominating the others during model training. The 'passthrough' remainder parameter retains any columns not explicitly transformed. Overall, this feature engineering setup prepares the input data for machine learning by encoding categorical variables and standardizing numerical features, optimizing them for subsequent model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify transformations\n",
    "\n",
    "feature_transformations = [\n",
    "                   ('One_Hot_Encode', OneHotEncoder(sparse_output=False, \n",
    "                                                    handle_unknown='ignore', \n",
    "                                                    drop='first', \n",
    "                                                    min_frequency=20\n",
    "                                                    ),\n",
    "                    ['Neighborhood','County', 'Type', 'Quality', 'Furnished']),\n",
    "                   ('Scaller', StandardScaler(), ['Size', 'Bathroom', 'Bedroom']), \n",
    "                   \n",
    "]\n",
    "# Create ColumnTransformer\n",
    "feature_engineering = ColumnTransformer(transformers=feature_transformations, remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling \n",
    "The Modeling phase stands as the juncture where data science transforms data into actionable insights. Through the tasks of selecting modeling techniques, generating test designs, building models, and assessing their performance, data scientists contribute to the creation of a model that aligns with the project's objectives. While the CRISP-DM Guide encourages iterative refinement until the best model is found, the practical reality often involves achieving a \"good enough\" model, advancing through the lifecycle, and continuously improving the model in subsequent iterations. This flexible approach ensures that the project remains adaptable to changing needs and ever-evolving datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 scores: [0.28988038 0.28067574 0.3443933  0.32960179 0.30887318]\n",
      "Mean R2 score: 0.31068487781860565\n",
      "MAE scores: [16749520.03254678 17001833.04615616 17108410.26626476 15731998.76657406\n",
      " 17289835.32797788]\n",
      "Mean MAE: 16776319.487903928\n",
      "RMSE scores: [34191901.12617593 37763612.33388431 35452583.16581678 31569276.8294648\n",
      " 38858630.49605058]\n",
      "Mean RMSE: 35567200.79027848\n"
     ]
    }
   ],
   "source": [
    "# Define the pipeline\n",
    "lr_transformations = Pipeline([\n",
    "    ('feature_engineering', feature_engineering),\n",
    "    ('pca', PCA(n_components=60, whiten=True)),\n",
    "    ('regr', LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "lr_transformations.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the trained model\n",
    "y_pred = lr_transformations.predict(X_test)\n",
    "\n",
    "# Evaluate the model using cross-validation and ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "# R2 score\n",
    "r2_scores = cross_val_score(lr_transformations, X_train, y_train, cv=cv, scoring='r2')\n",
    "print(f'R2 scores: {r2_scores}')\n",
    "print(f'Mean R2 score: {r2_scores.mean()}')\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae_scores = cross_val_score(lr_transformations, X_train, y_train, cv=cv, scoring='neg_mean_absolute_error')\n",
    "mae_scores = -mae_scores  # Take the negative and convert to positive\n",
    "print(f'MAE scores: {mae_scores}')\n",
    "print(f'Mean MAE: {mae_scores.mean()}')\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse_scores = cross_val_score(lr_transformations, X_train, y_train, cv=cv, scoring='neg_root_mean_squared_error')\n",
    "rmse_scores = -rmse_scores  # Take the negative and convert to positive\n",
    "print(f'RMSE scores: {rmse_scores}')\n",
    "print(f'Mean RMSE: {rmse_scores.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lr_model.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(lr_transformations, 'lr_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 scores: [0.23560641 0.00256675 0.25876112 0.22173936 0.23621453]\n",
      "Mean R2 score: 0.190977632582947\n",
      "MAE scores: [16126242.57586013 17187355.36349905 16994306.73782054 15833687.09498284\n",
      " 17666750.77230712]\n",
      "Mean MAE: 16761668.508893937\n",
      "RMSE scores: [35605604.10135386 45812202.84707737 37829264.05918647 34213206.84472663\n",
      " 40840664.77074244]\n",
      "Mean RMSE: 38860188.52461735\n"
     ]
    }
   ],
   "source": [
    "# Define the pipeline\n",
    "rf_transformations = Pipeline([\n",
    "    ('feature_engineering', feature_engineering),\n",
    "    ('pca', PCA(n_components=60, whiten=True)),\n",
    "    ('regr', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "rf_transformations.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the trained model\n",
    "y_pred = rf_transformations.predict(X_test)\n",
    "\n",
    "# Evaluate the model using cross-validation and ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "# R2 score\n",
    "r2_scores = cross_val_score(rf_transformations, X_train, y_train, cv=cv, scoring='r2')\n",
    "print(f'R2 scores: {r2_scores}')\n",
    "print(f'Mean R2 score: {r2_scores.mean()}')\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae_scores = cross_val_score(rf_transformations, X_train, y_train, cv=cv, scoring='neg_mean_absolute_error')\n",
    "mae_scores = -mae_scores  # Take the negative and convert to positive\n",
    "print(f'MAE scores: {mae_scores}')\n",
    "print(f'Mean MAE: {mae_scores.mean()}')\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse_scores = cross_val_score(rf_transformations, X_train, y_train, cv=cv, scoring='neg_root_mean_squared_error')\n",
    "rmse_scores = -rmse_scores  # Take the negative and convert to positive\n",
    "print(f'RMSE scores: {rmse_scores}')\n",
    "print(f'Mean RMSE: {rmse_scores.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_model.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(rf_transformations, 'rf_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG boostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 scores: [0.2647094  0.22921734 0.31855206 0.27093384 0.28032906]\n",
      "Mean R2 score: 0.27274834107233226\n",
      "MAE scores: [15853768.14091231 16074667.91089109 15989463.25304986 14522650.64382956\n",
      " 16334909.62164074]\n",
      "Mean MAE: 15755091.914064711\n",
      "RMSE scores: [34633200.75620892 38822053.30292863 36220977.91826513 32738165.36578636\n",
      " 39717687.76296422]\n",
      "Mean RMSE: 36426417.02123065\n",
      "Best PCA Components for XGBoost: 50\n",
      "Best XGBoost Hyperparameters: {'pca__n_components': 50, 'regr__learning_rate': 0.1, 'regr__max_depth': 3, 'regr__n_estimators': 50}\n",
      "r2_score (R2) for XGBoost: 29.54779654291594\n",
      "Mean Absolute Error (MAE) for XGBoost: 15440150.9270362\n",
      "Root Mean Squared Error (RMSE) for XGBoost: 38421357.60644769\n"
     ]
    }
   ],
   "source": [
    "# XGBoost transformations pipeline\n",
    "xg_transformations = Pipeline([\n",
    "    ('feature_engineering', feature_engineering),\n",
    "    ('pca', PCA()),\n",
    "    ('regr', XGBRegressor())\n",
    "])\n",
    "\n",
    "# Parameter grid for PCA components and XGBoost hyperparameters\n",
    "param_grid = {\n",
    "    'pca__n_components': [25, 50, 75, 100], \n",
    "    'regr__n_estimators': [50, 100, 150, 200],  \n",
    "    'regr__learning_rate': [0.01, 0.1, 0.2, 0.3], \n",
    "    'regr__max_depth': [3, 5, 7, 9], \n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for XGBoost\n",
    "xg_grid_search = GridSearchCV(xg_transformations, param_grid, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "xg_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best components and hyperparameters from the grid search\n",
    "best_components_xg = xg_grid_search.best_params_['pca__n_components']\n",
    "best_params_xg = xg_grid_search.best_params_\n",
    "\n",
    "# Set the best components and hyperparameters to the pipeline\n",
    "best_params_xg_regr = best_params_xg.get('regr', {})  # Retrieve 'regr' key safely\n",
    "xg_transformations.set_params(pca__n_components=best_components_xg,\n",
    "                              regr__n_estimators=best_params_xg_regr.get('n_estimators', 100),\n",
    "                              regr__learning_rate=best_params_xg_regr.get('learning_rate', 0.1),\n",
    "                              regr__max_depth=best_params_xg_regr.get('max_depth', 3))\n",
    "\n",
    "# Evaluate the model using cross-validation and ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "# R2 score\n",
    "r2_scores = cross_val_score(xg_transformations, X_train, y_train, cv=cv, scoring='r2')\n",
    "print(f'R2 scores: {r2_scores}')\n",
    "print(f'Mean R2 score: {r2_scores.mean()}')\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae_scores = cross_val_score(xg_transformations, X_train, y_train, cv=cv, scoring='neg_mean_absolute_error')\n",
    "mae_scores = -mae_scores  # Take the negative and convert to positive\n",
    "print(f'MAE scores: {mae_scores}')\n",
    "print(f'Mean MAE: {mae_scores.mean()}')\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse_scores = cross_val_score(xg_transformations, X_train, y_train, cv=cv, scoring='neg_root_mean_squared_error')\n",
    "rmse_scores = -rmse_scores  # Take the negative and convert to positive\n",
    "print(f'RMSE scores: {rmse_scores}')\n",
    "print(f'Mean RMSE: {rmse_scores.mean()}')\n",
    "\n",
    "# Fit the best model on the training data\n",
    "xg_transformations.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred_xg = xg_transformations.predict(X_test)\n",
    "\n",
    "# Print the best components, hyperparameters, and performance metrics\n",
    "print(f'Best PCA Components for XGBoost: {best_components_xg}')\n",
    "print(f'Best XGBoost Hyperparameters: {best_params_xg}')\n",
    "r2_xg = r2_score(y_test, y_pred_xg)\n",
    "mae_xg = mean_absolute_error(y_test, y_pred_xg)\n",
    "rmse_xg = np.sqrt(mean_squared_error(y_test, y_pred_xg))\n",
    "print(f'r2_score (R2) for XGBoost: {r2_xg * 100}')\n",
    "print(f'Mean Absolute Error (MAE) for XGBoost: {mae_xg}')\n",
    "print(f'Root Mean Squared Error (RMSE) for XGBoost: {rmse_xg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Xg_model.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(xg_transformations, 'Xg_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso and Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for Lasso: nan\n",
      "Mean Squared Error for Ridge: nan\n"
     ]
    }
   ],
   "source": [
    "# Lasso pipeline\n",
    "lasso_pipeline = Pipeline([\n",
    "    ('feature_engineering', feature_engineering),\n",
    "    ('pca', PCA()),\n",
    "    ('lasso', Lasso())\n",
    "])\n",
    "\n",
    "# Ridge pipeline\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('feature_engineering', feature_engineering),\n",
    "    ('pca', PCA()),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "# Parameter grids for Lasso and Ridge\n",
    "lasso_param_grid = {\n",
    "    'pca__n_components': np.arange(1, 101),  # PCA components\n",
    "    'lasso__alpha': [0.001, 0.01, 0.1, 1.0]  # Lasso alpha values\n",
    "}\n",
    "\n",
    "ridge_param_grid = {\n",
    "    'pca__n_components': np.arange(1, 101),  # PCA components\n",
    "    'ridge__alpha': [0.001, 0.01, 0.1, 1.0]  # Ridge alpha values\n",
    "}\n",
    "\n",
    "# Define scoring function (you can use R2, MAE, or RMSE)\n",
    "scoring = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Perform GridSearchCV for Lasso\n",
    "lasso_grid_search = GridSearchCV(lasso_pipeline, lasso_param_grid, scoring=scoring, cv=5)\n",
    "lasso_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Perform GridSearchCV for Ridge\n",
    "ridge_grid_search = GridSearchCV(ridge_pipeline, ridge_param_grid, scoring=scoring, cv=5)\n",
    "ridge_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best components and hyperparameters from the grid search for Lasso\n",
    "best_components_lasso = lasso_grid_search.best_params_['pca__n_components']\n",
    "best_alpha_lasso = lasso_grid_search.best_params_['lasso__alpha']\n",
    "\n",
    "# Get the best components and hyperparameters from the grid search for Ridge\n",
    "best_components_ridge = ridge_grid_search.best_params_['pca__n_components']\n",
    "best_alpha_ridge = ridge_grid_search.best_params_['ridge__alpha']\n",
    "\n",
    "# Set the best components and hyperparameters to the pipelines\n",
    "lasso_pipeline.set_params(pca__n_components=best_components_lasso, lasso__alpha=best_alpha_lasso)\n",
    "ridge_pipeline.set_params(pca__n_components=best_components_ridge, ridge__alpha=best_alpha_ridge)\n",
    "\n",
    "# Evaluate Lasso model using cross-validation and ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "# Lasso - Mean Squared Error\n",
    "lasso_scores = cross_val_score(lasso_pipeline, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "lasso_scores = -lasso_scores  # Take the negative and convert to positive\n",
    "print(f'Mean Squared Error for Lasso: {lasso_scores.mean()}')\n",
    "\n",
    "# Evaluate Ridge model using cross-validation and ShuffleSplit\n",
    "# Ridge - Mean Squared Error\n",
    "ridge_scores = cross_val_score(ridge_pipeline, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "ridge_scores = -ridge_scores  # Take the negative and convert to positive\n",
    "print(f'Mean Squared Error for Ridge: {ridge_scores.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ridge_model.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(lasso_pipeline, 'lasso_model.joblib')\n",
    "dump(ridge_pipeline, 'ridge_model.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'pca__n_components': 50, 'regr__max_depth': 10, 'regr__min_samples_split': 10, 'regr__n_estimators': 100}\n",
      "Mean Squared Error for RandomForestRegressor: 1356446933172605.0\n",
      "r2_score (R2): 26.487522540396657\n",
      "Mean Absolute Error (MAE): 16143117.944703292\n",
      "Root Mean Squared Error (RMSE): 39246953.04763636\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid for RandomForestRegressor\n",
    "param_grid = {\n",
    "    'pca__n_components': [50, 100, 150],  \n",
    "    'regr__n_estimators': [50, 100, 150],  \n",
    "    'regr__max_depth': [None, 10, 20],  \n",
    "    'regr__min_samples_split': [2, 5, 10]  \n",
    "}\n",
    "\n",
    "# RandomForestRegressor transformations pipeline\n",
    "rf_transformations_tuned = Pipeline([\n",
    "    ('feature_engineering', feature_engineering),\n",
    "    ('pca', PCA(whiten=True)),\n",
    "    ('regr', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "# Use ShuffleSplit for cross-validation\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform GridSearchCV for RandomForestRegressor\n",
    "grid_search = GridSearchCV(rf_transformations_tuned, param_grid, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Set the best parameters to the pipeline and fit on the training data\n",
    "rf_transformations_tuned.set_params(**best_params)\n",
    "rf_transformations_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate RandomForestRegressor model using cross-validation\n",
    "rf_scores = cross_val_score(rf_transformations_tuned, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "rf_scores = -rf_scores  # Take the negative and convert to positive\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred = rf_transformations_tuned.predict(X_test)\n",
    "\n",
    "# Print the best parameters and performance metrics\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Mean Squared Error for RandomForestRegressor: {rf_scores.mean()}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f'r2_score (R2): {r2 * 100}')\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_model_tuned.joblib']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(rf_transformations_tuned, 'rf_model_tuned.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model\n",
    "The base model, which incorporates feature engineering, dimensionality reduction via PCA (Principal Component Analysis) with 60 components, and linear regression, has been evaluated using various performance metrics. The R2 score, indicating the proportion of variance in the dependent variable explained by the model, is approximately 28.60%. The Mean Absolute Error (MAE) is calculated to be approximately 16,576,773.67, representing the average absolute difference between the predicted and actual values. The Root Mean Squared Error (RMSE), measuring the standard deviation of the residuals, is approximately 38,677,757.14. These metrics provide insights into the model's predictive accuracy and precision. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest Regressor\n",
    "The Random Forest Regressor model, implemented through the rf_transformations pipeline, has been evaluated on the provided metrics. The R2 score, a measure of the model's goodness of fit, is approximately 12.86%, indicating that the model explains a modest proportion of the variance in the target variable. The Mean Absolute Error (MAE) is found to be approximately 17,382,498.84, representing the average absolute difference between predicted and actual values. This metric provides insight into the model's accuracy, with lower values indicating better performance. Finally, the Root Mean Squared Error (RMSE) is approximately 42,729,236.45, serving as a measure of the model's prediction error, with lower values indicating better predictive accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
